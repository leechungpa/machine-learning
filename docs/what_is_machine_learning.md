# 머신러닝이란

우리는 무언가를 알고 싶다. 우리가 알기 쉽게. 그러기 위해 세상을 분석하고 통계를 이용해 설명한다. 하지만 그 정답을 우리가 이해하기 어려운 것들이 많다. 양자컴퓨팅에서는 두개의 상태가 동시에 존재할 수 있다. 무슨 말인지 우리는 이해하지 않지만, 관측 결과는 그렇다고 한다. 우리가 알고 싶어하는 그 세상을 이해하고자 노력하지만, 때로는 그 개념 자체가 어려워서 알기 어려운 것이 있다.

기존 주류 통계학은 세상을 이해하고자, 우리가 알고 있는 간단한 모델을 바탕으로 이해하고자 했다. 하지만 전부 우리가 직관적으로 이해할 수 있는 모델을 바탕으로 하지는 않는다. 그래서 우리가 그 원리는 정확히 이해하지 못하더라도, 기계적인 계산에 의해 세상을 이해할 방법은 없을까 생각했다. 우리의 머리로 이해하는 것이 아니라 기계(Artifical)의 지능을 활용해서 이해하고자 하는 시도가 머신러닝이다

실제로 우리가 이해하고있는 머신러닝의 알고리즘은 쉽게 이해하기 어렵다. 결과는 실제를 매우 잘 예측하지만 그 결과과 어떤 과정을 통해 도출 된 것인지 이해하기는 기존의 통계적 모델과 비교하자면 매우 어렵다. 물론 XAI라고 불리는 이 난해함을 이해하려는 시도도 존재한다

이런 머신러닝의 방법론으로 크게 3가지 방법이 있다. 먼저 우리가 예측하고자 하는 것을 알 수 있는 경우를 지도 학습이라고 불른다. 예를 들자면, 신용카드 회사에서 불량 고객을 판별하는 모델을 만들다고 한다면, 이전에 가지고 있는 데이터에 불량고객과 정상고객이라는 label을 가진 데이터가 있을 것이다. 이를 이용해 학습을 진행하는 것이 지도학습이다.

반면, 위의 예처럼 우리가 예측하고자 하는 것이 항상 있는 것만은 아니다. 이를 비지도 학습이라고 하며, 어떤 데이터를 가지고 비슷한 것을 찾고자 하는 경우가 있다. 예를 들자면 학생의 성적 및 종합적인 데이터를 바탕으로 해당학생이 비슷한 유형별로 묶은 후, 해당 학생에게 좋은 교육 방법을 제공해 주는 모델을 만들 수 있다. 실제 최근에 교육에도 이러한 빅데이터적인 기법을 활용하고자 하는 시도가 있다. 이런 것을 비지도 학습이라고 불른다.

이와 별도로 강화학습을 하나 더 말할 수 있다. 어떤 행동에 대해 올바른 방향으로 행동을 할경우 그 행동을 강화하게 만들고, 잘못된 방향으로 행동할 경우 그 행동을 약화하게 만드는 모델 알고리즘을 우리는 강화학습이라고 한다. 게임 등에 많이 활용되며, 자율주행차량이 올바르게 학습하는 것도 큰 의미의 강화학습이라고 말할 수 있다. 이러한 3가지 방법론을 가지고 머신러닝을 진행하게 된다.

기계학습은 데이터를 기반으로 모델을 만든다. 데이터를 바탕으로 학습데이터와 test 데이터를 분리하여 학습을 진행한다. 학습을 진행하기 위해서는 그 모델이 가지고 있는 cost를 줄이기 위해 노력한다. cost를 쉽게 말하면 우리의 모델을 바탕으로 한 예측이 실제와 얼마나 차이가 나는지를 확인한다고 보면 된다.

각각의 모델별로 어떤 모델을 만들지 영향을 주는 hyperparameter가 여러가지 존재한다. 해당 hyperparameter 별로 모델이 좋거나 나쁠 수 있는데 이는 test과정에서 진행하는 것이 아닌 학습의 과정에서 진행하게 된다. 그래서 train data라고 불리는 학습데이터를 다시 validation data set으로 분리하여 해당 validation data를 바탕으로 적절한 hyperparameter를 찾고자 노력한다. 그런데 이런 validation data를 어떻게 뽑냐에 따라 문제가 될 수 있으므로 여러개를 반복해서 validation을 진행할 수 있는데 이를 cross validation 이라고 한다.

여기서 test를 한다고 하는데 그것이 무엇을 의미하는지 말하고 마무리 하고자 한다. test를 하기 위해선 일반적으로 머신러닝에서는 모델을 이용한 미래의 예측이 실제 그 결과와 동일한지 비교해 본다. 그런데 어떤 경우에는 차이가 많이 나고, 어떤 경우에는 차이가 적게 나오는 경우가 있을 수 있다. 이러한 정도를 측정하고자 통계학에서 사용되는 variance 개념을 이용한다. 전반적으로 모든 데이터에 대해 좋은 결과를 보이는 것이 variance를 낮추는 경우이다.

기계학습은 variance 이외에 하나 더 고려한 부분이 있다. 바로 overfitting의 문제이다. 기계학습은 일반적으로 데이터를 바탕으로 학습을 진행하게 된다. 따라서 모형이 아주 복잡해질 경우, 전체 세상의 일부인 데이터가 아니라 그 데이터가 전체 세상인것처럼, 데이터 만으로 모델을 만들게 된다. 즉 우리가 가지고 있는 데이터가 outlier를 포함하고 있을 것인데, 해당 outlier에도 매우 민감한 모델을 만들 수 있다. 이것을 보고 우리는 overfitting 이라고 말한다.
